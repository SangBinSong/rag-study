"""
RAG Study Streamlit App - Web UI for Document Loading and Vector Search
"""

import streamlit as st
import os
from pathlib import Path
import tempfile
from module.document_parser import load_documents
from module.vector_db import VectorDB

# Page config
st.set_page_config(
    page_title="RAG Study Demo",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize session state
if 'documents' not in st.session_state:
    st.session_state.documents = None
if 'vector_db' not in st.session_state:
    st.session_state.vector_db = None
if 'db_path' not in st.session_state:
    st.session_state.db_path = "./db/streamlit_rag_demo"

def init_vector_db():
    """Initialize vector database"""
    if st.session_state.vector_db is None:
        st.session_state.vector_db = VectorDB(storage_path=st.session_state.db_path)
    return st.session_state.vector_db

def main():
    st.title("ğŸ” RAG Study Demo")
    st.markdown("**Magika AI ê¸°ë°˜ ë¬¸ì„œ ë¡œë”© + FAISS ë²¡í„° ê²€ìƒ‰**")
    
    # Sidebar for configuration
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # OpenAI API Key
        openai_key = st.text_input(
            "OpenAI API Key", 
            type="password",
            value=os.getenv('OPENAI_API_KEY', ''),
            help="ì„ë² ë”© ìƒì„±ì„ ìœ„í•œ OpenAI API í‚¤"
        )
        if openai_key:
            os.environ['OPENAI_API_KEY'] = openai_key
        
        # Chunk settings
        st.subheader("ğŸ“ ì²­í¬ ì„¤ì •")
        chunk_size = st.slider("ì²­í¬ í¬ê¸°", 500, 2000, 1000, 100)
        chunk_overlap = st.slider("ì²­í¬ ì˜¤ë²„ë©", 50, 500, 200, 50)
        
        st.divider()
        
        # Vector DB info
        st.subheader("ğŸ—‚ï¸ ë²¡í„° DB ìƒíƒœ")
        if st.button("ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨"):
            if st.session_state.vector_db:
                stats = st.session_state.vector_db.get_stats()
                st.json(stats)
    
    # Check API key
    if not os.getenv('OPENAI_API_KEY'):
        st.warning("âš ï¸ OpenAI API í‚¤ë¥¼ ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •í•´ì£¼ì„¸ìš”!")
        return
    
    # Main tabs
    tab1, tab2, tab3 = st.tabs(["ğŸ“„ ë¬¸ì„œ ë¡œë”©", "ğŸ—‚ï¸ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤", "ğŸ” ê²€ìƒ‰"])
    
    with tab1:
        st.header("ğŸ“„ ë¬¸ì„œ ë¡œë”©")
        
        # File upload options
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
            uploaded_file = st.file_uploader(
                "ë¬¸ì„œ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
                type=['pdf', 'txt', 'docx', 'pptx', 'xlsx', 'csv', 'md', 'html', 'json'],
                help="Magika AIê°€ íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ íƒ€ì…ì„ ê²°ì •í•©ë‹ˆë‹¤"
            )
        
        with col2:
            st.subheader("ğŸ“‚ ìƒ˜í”Œ íŒŒì¼")
            sample_path = "sample/êµ­ê°€ë³„ ê³µê³µë¶€ë¬¸ AI ë„ì… ë° í™œìš© ì „ëµ.pdf"
            if Path(sample_path).exists():
                if st.button("ğŸ‡°ğŸ‡· ìƒ˜í”Œ PDF ì‚¬ìš©", type="primary"):
                    st.session_state.selected_file = sample_path
                    st.success(f"ìƒ˜í”Œ íŒŒì¼ ì„ íƒë¨: {sample_path}")
            else:
                st.error(f"ìƒ˜í”Œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {sample_path}")
        
        # Process file
        file_to_process = None
        
        if uploaded_file:
            # Save uploaded file temporarily
            with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{uploaded_file.name}") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                file_to_process = tmp_file.name
                st.info(f"ğŸ“¤ ì—…ë¡œë“œë¨: {uploaded_file.name}")
        
        elif hasattr(st.session_state, 'selected_file'):
            file_to_process = st.session_state.selected_file
        
        if file_to_process and st.button("ğŸš€ ë¬¸ì„œ ë¡œë”© ì‹¤í–‰", type="primary"):
            try:
                with st.spinner("ğŸ“Š Magika AIë¡œ ë¬¸ì„œ ë¶„ì„ ì¤‘..."):
                    documents = load_documents(
                        file_to_process, 
                        chunk_size=chunk_size, 
                        chunk_overlap=chunk_overlap,
                        split_documents=True
                    )
                    
                st.session_state.documents = documents
                
                # Show results
                st.success(f"âœ… ì„±ê³µ! {len(documents)}ê°œ ì²­í¬ë¡œ ë¶„í• ë¨")
                
                # Document statistics
                if documents:
                    # Calculate statistics
                    total_chars = sum(len(doc.page_content) for doc in documents)
                    detected_types = {}
                    detection_methods = {'magika': 0}
                    
                    for doc in documents:
                        detected_type = doc.metadata.get('detected_type', 'unknown')
                        detected_types[detected_type] = detected_types.get(detected_type, 0) + 1
                        detection_methods['magika'] += 1
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ì´ ë¬¸ì„œ", len(documents))
                    with col2:
                        st.metric("ì´ ë¬¸ì ìˆ˜", f"{total_chars:,}")
                    with col3:
                        st.metric("í‰ê·  ì²­í¬ ê¸¸ì´", f"{total_chars // len(documents):,}")
                    with col4:
                        st.metric("ì†ŒìŠ¤ íŒŒì¼", len(set(doc.metadata.get('source', 'unknown') for doc in documents)))
                    
                    # File type detection
                    st.subheader("ğŸ” Magika ê²€ì¶œ ê²°ê³¼")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.json({"ê²€ì¶œëœ íƒ€ì…": detected_types})
                    with col2:
                        st.json({"ê²€ì¶œ ë°©ì‹": detection_methods})
                    
                    # Sample content
                    with st.expander("ğŸ“– ì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°"):
                        first_doc = documents[0]
                        st.text(first_doc.page_content[:500] + "..." if len(first_doc.page_content) > 500 else first_doc.page_content)
                        st.json(first_doc.metadata)
                        
            except Exception as e:
                st.error(f"âŒ ë¬¸ì„œ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            
            finally:
                # Clean up temporary file
                if uploaded_file and file_to_process and Path(file_to_process).exists():
                    try:
                        os.unlink(file_to_process)
                    except:
                        pass
    
    with tab2:
        st.header("ğŸ—‚ï¸ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤")
        
        # Initialize vector DB
        vector_db = init_vector_db()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“Š í˜„ì¬ ìƒíƒœ")
            stats = vector_db.get_stats()
            st.json(stats)
            
            is_empty = vector_db.is_empty()
            if is_empty:
                st.info("ğŸ“­ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            else:
                st.success("ğŸ“š ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤")
        
        with col2:
            st.subheader("ğŸ”§ ì‘ì—…")
            
            # Add documents
            if st.session_state.documents:
                if st.button("ğŸ“ ë¬¸ì„œ ì¶”ê°€", type="primary"):
                    try:
                        with st.spinner("ë²¡í„° ì„ë² ë”© ìƒì„± ì¤‘..."):
                            # Add first 20 chunks for demo
                            docs_to_add = st.session_state.documents[:20]
                            vector_db.add_documents(docs_to_add)
                        
                        st.success(f"âœ… {len(docs_to_add)}ê°œ ë¬¸ì„œ ì²­í¬ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()
                    except Exception as e:
                        st.error(f"âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {str(e)}")
            else:
                st.warning("âš ï¸ ë¨¼ì € ë¬¸ì„œë¥¼ ë¡œë”©í•´ì£¼ì„¸ìš”")
            
            # Save to disk
            if not is_empty:
                if st.button("ğŸ’¾ ë””ìŠ¤í¬ì— ì €ì¥"):
                    try:
                        vector_db.save()
                        st.success("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ë””ìŠ¤í¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    except Exception as e:
                        st.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            
            # Clear database
            if st.button("ğŸ—‘ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”", type="secondary"):
                st.session_state.vector_db = None
                st.success("ğŸ”„ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
    
    with tab3:
        st.header("ğŸ” ìœ ì‚¬ë„ ê²€ìƒ‰")
        
        vector_db = init_vector_db()
        
        if vector_db.is_empty():
            st.warning("âš ï¸ ë¨¼ì € ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€í•´ì£¼ì„¸ìš”!")
            return
        
        # Initialize query in session state
        if 'search_query' not in st.session_state:
            st.session_state.search_query = ""
        
        # Predefined queries
        st.subheader("ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("AI ë„ì… ì „ëµ"):
                st.session_state.search_query = "AI ë„ì… ì „ëµì€ ë¬´ì—‡ì¸ê°€?"
        with col2:
            if st.button("ê³µê³µë¶€ë¬¸ ì¸ê³µì§€ëŠ¥"):
                st.session_state.search_query = "ê³µê³µë¶€ë¬¸ì—ì„œì˜ ì¸ê³µì§€ëŠ¥ í™œìš©"
        with col3:
            if st.button("ë””ì§€í„¸ ì „í™˜"):
                st.session_state.search_query = "ë””ì§€í„¸ ì „í™˜ê³¼ í˜ì‹ "
        
        # Search interface
        col1, col2 = st.columns([3, 1])
        
        with col1:
            query = st.text_input(
                "ğŸ” ê²€ìƒ‰í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”",
                value=st.session_state.search_query,
                placeholder="ì˜ˆ: AI ë„ì… ì „ëµì€ ë¬´ì—‡ì¸ê°€ìš”?",
                key="query_input"
            )
            # Update session state when user types
            if query != st.session_state.search_query:
                st.session_state.search_query = query
        
        with col2:
            k = st.selectbox("ê²°ê³¼ ê°œìˆ˜", [3, 5, 10], index=1)
        
        # Search execution
        if query and st.button("ğŸš€ ê²€ìƒ‰ ì‹¤í–‰", type="primary"):
            try:
                with st.spinner("ğŸ” ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘..."):
                    results = vector_db.similarity_search(query, k=k)
                
                if results:
                    st.success(f"âœ… {len(results)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    
                    for i, doc in enumerate(results, 1):
                        with st.expander(f"ğŸ“„ ê²°ê³¼ {i}", expanded=i <= 3):
                            # Content
                            st.markdown("**ë‚´ìš©:**")
                            st.text(doc.page_content)
                            
                            # Metadata
                            st.markdown("**ë©”íƒ€ë°ì´í„°:**")
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("íŒŒì¼ëª…", doc.metadata.get('file_name', 'N/A'))
                            with col2:
                                st.metric("ê²€ì¶œ íƒ€ì…", doc.metadata.get('detected_type', 'N/A'))
                            with col3:
                                st.metric("íŒŒì¼ í¬ê¸°", f"{doc.metadata.get('file_size', 0):,} bytes")
                else:
                    st.warning("ğŸ¤” ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")

if __name__ == "__main__":
    main()